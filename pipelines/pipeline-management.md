# Pipeline management

**Pipelines** are the data streaming heart of Datamin. The UI canvas and the powerful engine behind it allow our users to orchestrate the entire process between receiving input data from outside to sending it to a destination. It is also a place where you will spend most of your time at Datamin.

Pipeline management canvas is a drag-and-drop no-code interface where you can create tasks, connect them, configure each task, and run and schedule pipelines.

<figure><img src="../.gitbook/assets/Screenshot 2024-04-29 at 14.52.47.png" alt=""><figcaption></figcaption></figure>

In the next pages you will learn about:

* 13 types of [tasks](tasks-ip/) you can build your pipelines from
* How to [schedule](running-and-scheduling-workflows.md#automatically-by-a-schedule) pipelines, trigger [in real-time](running-and-scheduling-workflows.md#in-real-time-from-apache-kafka-rabbitmq-google-pub-sub-etc), [on-demand](running-and-scheduling-workflows.md#manually-on-demand) or via [our API](running-and-scheduling-workflows.md#automatically-via-api.)
* How to use the [library or templates](library-of-templates.md)
* How to expand the functionality of your pipelines with [environment variables](environment-variables.md), [mathematical functions](mathematical-functions.md), and [formatted messages](formatting-of-messages.md).
